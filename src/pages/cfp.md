---
title: Call for Papers
---

# Call for Papers
<h2 class="subheader">FATREC Workshop on Responsible Recommendation</h2>

The FATREC Workshop on Responsible Recommendation at RecSys 2017 is a venue for discussing questions of social responsibility in building, maintaining, evaluating, and studying recommender systems. This will be an interactive workshop with position papers, research papers, and discussion about how ethical, social, and legal concerns impact recommender systems research and development, hoping to result in an agenda for research on socially responsible recommendation. 

FATREC stands for Fairness, Accountability and Transparency in Recommender Systems and aims to draw attention to these issues at ACM RecSys 2016, as has been done in the machine learning community through events such as [FATML](http://www.fatml.org/). There are many potential aspects of responsibility in recommendation, including (but not limited to):

- Bias and discrimination in recommendations
- Imbalance in meeting the needs of different groups of users
- Balancing needs of users versus recommendation system owners
- Ethics of explore/exploit strategies or A/B testing
- ‘Filter bubble’ or ‘balkanization’ effects
- Clickbait
- Transparent and accurate explanations for recommendations
- User data privacy

We invite the following types of papers:

**Position papers** 2–4 pages in length addressing one or more of the following themes:

- *Responsibility* — what does it mean for a recommender system to be socially responsible? How can we assess the social and human impact of recommender systems?
- *Fairness* — what might ‘fairness’ mean in the context of recommendation? How could a recommender be unfair, and how could we measure such unfairness?
- *Accountability* — to whom, and under what standard, should a recommender system be accountable? How can or should it and its operators be held accountable? What harms should such accountability be designed to prevent?
- *Transparency* — what is the value of transparency in recommendation, and how might it be achieved? How might it trade off with other important concerns?

**Research papers** up to 6 pages in length presenting empirical or analytical results related to the social impact of recommender systems or algorithms. These could be explorations of bias in recommender systems (either live systems or sandboxed algorithms), explainability and transparency of recommender systems, experiments regarding the impact of the recommender on its users or others, etc. We will construe the topics broadly.

Papers will be reviewed by a program committee, and accepted papers will be published through Boise State University ScholarWorks (each paper will have its own DOI and be indexed by Google Scholar and similar services).

Submit papers in ACM SIG format [via EasyChair](https://easychair.org/conferences/?conf=fatrec2017).

**Important Dates:**

- **June 22** — papers due
- **July 13** — acceptance notification
- **July 28** — camera-ready versions due
