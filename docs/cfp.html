
<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FATREC 2017 - Call for Papers</title>
    <link rel="icon" title="FATREC" href="assets/img/like-q.png">
    <link rel="stylesheet" href="assets/css/app.css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,400i,700,700i" rel="stylesheet">
  </head>
  <body>
    <nav class="top-bar">
      <div class="top-bar-title site-title">
        <a href="./">FATREC</a> @ <a href="http://recsys.acm.org/recsys17/">RecSys 2017</a>
      </div>
      <div class="top-bar-right">
        <ul class="menu">
          <li><a href="program.html">Program</a>
          </li><li><a href="cfp.html">Call</a>
          </li><li><a href="committee.html">Committee</a>
          </li><li><a href="https://twitter.com/FAccTRec"><img src="assets/img/twitter.png" style="height: 1em;"></a>
        </li></ul>
      </div>
    </nav>
    <div class="row">
      <div class="large-10 large-offset-1 medium-12 columns end">
        
        <h1>Call for Papers</h1>
        <p></p><h2 class="subheader">FATREC Workshop on Responsible Recommendation</h2><p></p>
        <p>The FATREC Workshop on Responsible Recommendation at RecSys 2017 is a venue for discussing questions of social responsibility in building, maintaining, evaluating, and studying recommender systems. This will be an interactive workshop with position papers, research papers, and discussion about how ethical, social, and legal concerns impact recommender systems research and development, hoping to result in an agenda for research on socially responsible recommendation.</p>
        <p>FATREC stands for Fairness, Accountability and Transparency in Recommender Systems and aims to draw attention to these issues at ACM RecSys 2016, as has been done in the machine learning community through events such as <a href="http://www.fatml.org/">FATML</a>. There are many potential aspects of responsibility in recommendation, including (but not limited to):</p>
        <ul>
        <li>Bias and discrimination in recommendations</li>
        <li>Imbalance in meeting the needs of different groups of users</li>
        <li>Balancing needs of users versus recommendation system owners</li>
        <li>Ethics of explore/exploit strategies or A/B testing</li>
        <li>‘Filter bubble’ or ‘balkanization’ effects</li>
        <li>Clickbait</li>
        <li>Transparent and accurate explanations for recommendations</li>
        <li>User data privacy</li>
        </ul>
        <p>We invite the following types of papers:</p>
        <p><strong>Position papers</strong> 2–4 pages in length addressing one or more of the following themes:</p>
        <ul>
        <li><em>Responsibility</em> — what does it mean for a recommender system to be socially responsible? How can we assess the social and human impact of recommender systems?</li>
        <li><em>Fairness</em> — what might ‘fairness’ mean in the context of recommendation? How could a recommender be unfair, and how could we measure such unfairness?</li>
        <li><em>Accountability</em> — to whom, and under what standard, should a recommender system be accountable? How can or should it and its operators be held accountable? What harms should such accountability be designed to prevent?</li>
        <li><em>Transparency</em> — what is the value of transparency in recommendation, and how might it be achieved? How might it trade off with other important concerns?</li>
        </ul>
        <p>We also welcome up to 2 page abstracts that describe practical issues in building responsible recommendations. These could be both research systems or production systems in industry.</p>
        <p><strong>Research papers</strong> up to 6 pages in length presenting empirical or analytical results related to the social impact of recommender systems or algorithms. These could be explorations of bias in recommender systems (either live systems or sandboxed algorithms), explainability and transparency of recommender systems, experiments regarding the impact of the recommender on its users or others, etc. We will construe the topics broadly.</p>
        <p>Papers will be reviewed by a program committee, and accepted papers will be published through Boise State University ScholarWorks (each paper will have its own DOI and be indexed by Google Scholar and similar services).</p>
        <p>Submit papers in ACM SIG format <a href="https://easychair.org/conferences/?conf=fatrec2017">via EasyChair</a>.</p>
        <p><strong>Important Dates:</strong></p>
        <ul>
        <li><strong>June 22</strong> — papers due</li>
        <li><strong>July 13</strong> — acceptance notification</li>
        <li><strong>July 28</strong> — camera-ready versions due</li>
        </ul>
        
      </div>
    </div>

    <script src="assets/js/app.js"></script>
  </body>
</html>